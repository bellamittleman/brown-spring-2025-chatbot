import os
import time
import json
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# OpenAI Client (ensure API Key is correctly set)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Directory containing JSONL files
JSONL_DIR = "jsonl_files"
MERGED_JSONL_FILE = "merged_data.jsonl"  # The final merged file


def merge_jsonl_files():
    """Merges all JSONL files into a single large JSONL file."""
    merged_data = []
    
    for jsonl_file in os.listdir(JSONL_DIR):
        if jsonl_file.endswith(".jsonl"):
            file_path = os.path.join(JSONL_DIR, jsonl_file)
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    for line in f:
                        try:
                            json_obj = json.loads(line.strip())  # Validate JSON
                            merged_data.append(json_obj)
                        except json.JSONDecodeError:
                            print(f"‚ùå Skipping invalid JSON line in {jsonl_file}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error reading {jsonl_file}: {e}")

    # Write merged data to a new JSONL file
    if merged_data:
        with open(MERGED_JSONL_FILE, "w", encoding="utf-8") as f:
            for obj in merged_data:
                f.write(json.dumps(obj, ensure_ascii=False) + "\n")
        print(f"‚úÖ Merged {len(merged_data)} records into {MERGED_JSONL_FILE}")
    else:
        print("‚ö†Ô∏è No valid JSONL data found. Exiting.")
        return None
    
    return MERGED_JSONL_FILE


def upload_jsonl_file(file_path):
    """Uploads the merged JSONL file for fine-tuning."""
    try:
        with open(file_path, "rb") as f:
            response = client.files.create(file=f, purpose="fine-tune")
            file_id = response.id
            print(f"üì§ Uploaded {file_path} ‚Üí File ID: {file_id}")
            return file_id
    except Exception as e:
        print(f"‚ö†Ô∏è Error uploading file: {e}")
        return None


def fine_tune_model(file_id):
    """Creates a fine-tuning job using the uploaded file."""
    if not file_id:
        print("‚ùå No file uploaded for fine-tuning. Exiting.")
        return None

    response = client.fine_tuning.jobs.create(
        training_file=file_id,
        model="gpt-3.5-turbo-1106",  # Adjust for GPT-4o if needed
        hyperparameters={
            "n_epochs": 3,
            "batch_size": "auto",
            "learning_rate_multiplier": "auto"
        }
    )

    job_id = response.id
    print(f"üöÄ Fine-tuning job created: {job_id}")
    return job_id


def track_fine_tuning_status(job_id):
    """Monitors the fine-tuning job until completion."""
    if not job_id:
        print("‚ùå No fine-tuning job found.")
        return

    while True:
        job = client.fine_tuning.jobs.retrieve(job_id)
        print(f"‚è≥ Status: {job.status}")

        if job.status in ["succeeded", "failed"]:
            print(f"‚úÖ Final status: {job.status}")
            if job.status == "succeeded":
                print(f"üéØ Fine-tuned model ID: {job.fine_tuned_model}")
            break

        time.sleep(60)  # Check status every 60 seconds


if __name__ == "__main__":
    print("\nüöÄ Starting fine-tuning process...\n")

    # Step 1: Merge JSONL files
    merged_file = merge_jsonl_files()
    if not merged_file:
        exit()

    # Step 2: Upload merged JSONL file
    file_id = upload_jsonl_file(merged_file)

    # Step 3: Start fine-tuning
    job_id = fine_tune_model(file_id)

    # Step 4: Track fine-tuning progress
    track_fine_tuning_status(job_id)

    print("\n‚úÖ Fine-tuning process complete.\n")
